{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPxT3XMI8O3RFBy4YOMtM+n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DhruboDevPramanik/FL_with_MINST_dataset/blob/main/part1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2pO87RbevjmU",
        "outputId": "255e6fdc-1db3-4109-9da4-fb140306bfc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Collecting flwr\n",
            "  Downloading flwr-1.21.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Collecting click<8.2.0 (from flwr)\n",
            "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting cryptography<45.0.0,>=44.0.1 (from flwr)\n",
            "  Downloading cryptography-44.0.3-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: grpcio!=1.65.0,<2.0.0,>=1.62.3 in /usr/local/lib/python3.12/dist-packages (from flwr) (1.74.0)\n",
            "Collecting grpcio-health-checking<2.0.0,>=1.62.3 (from flwr)\n",
            "  Downloading grpcio_health_checking-1.75.0-py3-none-any.whl.metadata (1.0 kB)\n",
            "Collecting iterators<0.0.3,>=0.0.2 (from flwr)\n",
            "  Downloading iterators-0.0.2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting pathspec<0.13.0,>=0.12.1 (from flwr)\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting protobuf<5.0.0,>=4.21.6 (from flwr)\n",
            "  Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Collecting pycryptodome<4.0.0,>=3.18.0 (from flwr)\n",
            "  Downloading pycryptodome-3.23.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=6.0.2 in /usr/local/lib/python3.12/dist-packages (from flwr) (6.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.12/dist-packages (from flwr) (2.32.4)\n",
            "Requirement already satisfied: rich<14.0.0,>=13.5.0 in /usr/local/lib/python3.12/dist-packages (from flwr) (13.9.4)\n",
            "Collecting tomli<3.0.0,>=2.0.1 (from flwr)\n",
            "  Downloading tomli-2.2.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting tomli-w<2.0.0,>=1.0.0 (from flwr)\n",
            "  Downloading tomli_w-1.2.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting typer<0.13.0,>=0.12.5 (from flwr)\n",
            "  Downloading typer-0.12.5-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography<45.0.0,>=44.0.1->flwr) (2.0.0)\n",
            "INFO: pip is looking at multiple versions of grpcio-health-checking to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting grpcio-health-checking<2.0.0,>=1.62.3 (from flwr)\n",
            "  Downloading grpcio_health_checking-1.74.0-py3-none-any.whl.metadata (1.0 kB)\n",
            "  Downloading grpcio_health_checking-1.73.1-py3-none-any.whl.metadata (1.0 kB)\n",
            "  Downloading grpcio_health_checking-1.73.0-py3-none-any.whl.metadata (1.0 kB)\n",
            "  Downloading grpcio_health_checking-1.72.2-py3-none-any.whl.metadata (1.0 kB)\n",
            "  Downloading grpcio_health_checking-1.72.1-py3-none-any.whl.metadata (1.0 kB)\n",
            "  Downloading grpcio_health_checking-1.71.2-py3-none-any.whl.metadata (1.0 kB)\n",
            "  Downloading grpcio_health_checking-1.71.0-py3-none-any.whl.metadata (1.0 kB)\n",
            "INFO: pip is still looking at multiple versions of grpcio-health-checking to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading grpcio_health_checking-1.70.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_health_checking-1.69.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_health_checking-1.68.1-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_health_checking-1.68.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_health_checking-1.67.1-py3-none-any.whl.metadata (1.1 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading grpcio_health_checking-1.67.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_health_checking-1.66.2-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_health_checking-1.66.1-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_health_checking-1.66.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_health_checking-1.65.5-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_health_checking-1.65.4-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_health_checking-1.65.2-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_health_checking-1.65.1-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_health_checking-1.64.3-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_health_checking-1.64.1-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_health_checking-1.64.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_health_checking-1.63.2-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_health_checking-1.63.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_health_checking-1.62.3-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.31.0->flwr) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.31.0->flwr) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.31.0->flwr) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.31.0->flwr) (2025.8.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich<14.0.0,>=13.5.0->flwr) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich<14.0.0,>=13.5.0->flwr) (2.19.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<0.13.0,>=0.12.5->flwr) (1.5.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography<45.0.0,>=44.0.1->flwr) (2.23)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.5.0->flwr) (0.1.2)\n",
            "Downloading flwr-1.21.0-py3-none-any.whl (664 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.2/664.2 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading click-8.1.8-py3-none-any.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cryptography-44.0.3-cp39-abi3-manylinux_2_34_x86_64.whl (4.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m83.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading grpcio_health_checking-1.62.3-py3-none-any.whl (18 kB)\n",
            "Downloading iterators-0.0.2-py3-none-any.whl (3.9 kB)\n",
            "Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycryptodome-3.23.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m90.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomli-2.2.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (242 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.3/242.3 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomli_w-1.2.0-py3-none-any.whl (6.7 kB)\n",
            "Downloading typer-0.12.5-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.3/47.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tomli-w, tomli, pycryptodome, protobuf, pathspec, iterators, click, grpcio-health-checking, cryptography, typer, flwr\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.5\n",
            "    Uninstalling protobuf-5.29.5:\n",
            "      Successfully uninstalled protobuf-5.29.5\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.2.1\n",
            "    Uninstalling click-8.2.1:\n",
            "      Successfully uninstalled click-8.2.1\n",
            "  Attempting uninstall: cryptography\n",
            "    Found existing installation: cryptography 43.0.3\n",
            "    Uninstalling cryptography-43.0.3:\n",
            "      Successfully uninstalled cryptography-43.0.3\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.17.4\n",
            "    Uninstalling typer-0.17.4:\n",
            "      Successfully uninstalled typer-0.17.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "pyopenssl 24.2.1 requires cryptography<44,>=41.0.5, but you have cryptography 44.0.3 which is incompatible.\n",
            "pydrive2 1.21.3 requires cryptography<44, but you have cryptography 44.0.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed click-8.1.8 cryptography-44.0.3 flwr-1.21.0 grpcio-health-checking-1.62.3 iterators-0.0.2 pathspec-0.12.1 protobuf-4.25.8 pycryptodome-3.23.0 tomli-2.2.1 tomli-w-1.2.0 typer-0.12.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "d0242cf1610f41e5b620bb7a49856911"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Cell 1: Install required packages\n",
        "!pip install torch torchvision flwr"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Import all required libraries\n",
        "from collections import OrderedDict\n",
        "from typing import Dict, List, Tuple\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision.transforms import ToTensor, Normalize, Compose\n",
        "from torchvision.datasets import MNIST\n",
        "import flwr as fl\n",
        "from flwr.common import NDArrays, Scalar\n",
        "import numpy as np"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zG4GkyZ6vpn1",
        "outputId": "5af919f7-fbec-4461-c867-bb543e5c4b2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Define the neural network model\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, num_classes: int) -> None:\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, num_classes)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 4 * 4)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "6X_qaR1kvs33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Training and testing functions\n",
        "def train(net, trainloader, optimizer, epochs, device: str):\n",
        "    \"\"\"Train the network on the training set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    net.to(device)\n",
        "    net.train()\n",
        "    for e in range(epochs):\n",
        "        for images, labels in trainloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            loss = criterion(net(images), labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "def test(net, testloader, device: str):\n",
        "    \"\"\"Validate the network on the entire test set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    correct, total, loss = 0, 0, 0.0\n",
        "    net.to(device)\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        for images, labels in testloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = net(images)\n",
        "            loss += criterion(outputs, labels).item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = correct / total\n",
        "    return loss, accuracy"
      ],
      "metadata": {
        "id": "UC90Ouk3vwB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Dataset preparation functions\n",
        "def get_mnist(data_path: str = \"./data\"):\n",
        "    tr = Compose([ToTensor(), Normalize((0.1307,), (0.3081,))])\n",
        "    trainset = MNIST(root=data_path, train=True, download=True, transform=tr)\n",
        "    testset = MNIST(root=data_path, train=False, download=True, transform=tr)\n",
        "    return trainset, testset\n",
        "\n",
        "def prepare_dataset(num_partitions: int, batch_size: int, val_ratio: float = 0.1):\n",
        "    trainset, testset = get_mnist()\n",
        "\n",
        "    # Split the dataset into num_partitions parts\n",
        "    num_image = len(trainset) // num_partitions\n",
        "    partition_len = [num_image] * num_partitions\n",
        "\n",
        "    trainsets = random_split(trainset, partition_len, torch.Generator().manual_seed(2023))\n",
        "\n",
        "    # Create dataloaders with train + val split\n",
        "    trainloaders = []\n",
        "    validateloaders = []\n",
        "    for trainset_ in trainsets:\n",
        "        num_total = len(trainset_)\n",
        "        num_val = int(num_total * val_ratio)\n",
        "        num_train = num_total - num_val\n",
        "\n",
        "        for_train, for_val = random_split(trainset_, [num_train, num_val], torch.Generator().manual_seed(2023))\n",
        "\n",
        "        trainloaders.append(DataLoader(for_train, batch_size=batch_size, shuffle=True))\n",
        "        validateloaders.append(DataLoader(for_val, batch_size=batch_size, shuffle=False))\n",
        "\n",
        "    testloader = DataLoader(testset, batch_size=128)\n",
        "    return trainloaders, validateloaders, testloader"
      ],
      "metadata": {
        "id": "lb9hupCMvx2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Flower client class with validation tracking\n",
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, trainloader, valloader, num_classes) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.trainloader = trainloader\n",
        "        self.valloader = valloader\n",
        "\n",
        "        self.model = Net(num_classes)\n",
        "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model.to(self.device)\n",
        "\n",
        "    def set_parameters(self, parameters):\n",
        "        params_dict = zip(self.model.state_dict().keys(), parameters)\n",
        "        state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
        "        self.model.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "    def get_parameters(self, config: Dict[str, Scalar] = None):\n",
        "        return [val.cpu().numpy() for _, val in self.model.state_dict().items()]\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        self.set_parameters(parameters)\n",
        "\n",
        "        lr = config[\"lr\"]\n",
        "        momentum = config[\"momentum\"]\n",
        "        epochs = config[\"local_epochs\"]\n",
        "\n",
        "        optim = torch.optim.SGD(self.model.parameters(), lr=lr, momentum=momentum)\n",
        "\n",
        "        # Do local training\n",
        "        train(self.model, self.trainloader, optim, epochs, self.device)\n",
        "\n",
        "        return self.get_parameters(), len(self.trainloader.dataset), {}\n",
        "\n",
        "    def evaluate(self, parameters: NDArrays, config: Dict[str, Scalar]):\n",
        "        self.set_parameters(parameters)\n",
        "\n",
        "        loss, accuracy = test(self.model, self.valloader, self.device)\n",
        "\n",
        "        # Print validation accuracy for this client\n",
        "        print(f\"Client validation - Loss: {loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "        return float(loss), len(self.valloader.dataset), {\"accuracy\": float(accuracy)}\n",
        "\n",
        "def generate_client_fn(trainloaders, valloaders, num_classes):\n",
        "    def client_fn(cid: str):\n",
        "        return FlowerClient(\n",
        "            trainloader=trainloaders[int(cid)],\n",
        "            valloader=valloaders[int(cid)],\n",
        "            num_classes=num_classes,\n",
        "        )\n",
        "    return client_fn"
      ],
      "metadata": {
        "id": "_DS_iPXev0lL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7: Server functions with validation tracking\n",
        "def get_on_fit_config(config):\n",
        "    def fit_config_fn(server_round: int):\n",
        "        return {\n",
        "            'lr': config['lr'],\n",
        "            'momentum': config['momentum'],\n",
        "            'local_epochs': config['local_epochs'],\n",
        "        }\n",
        "    return fit_config_fn\n",
        "\n",
        "def get_evaluate_fn(num_classes, testloader):\n",
        "    def evaluate_fn(server_round: int, parameters, config):\n",
        "        model = Net(num_classes)\n",
        "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        params_dict = zip(model.state_dict().keys(), parameters)\n",
        "        state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
        "        model.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "        loss, accuracy = test(model, testloader, device)\n",
        "\n",
        "        # Print global test accuracy\n",
        "        print(f\"Global test - Round {server_round}: Loss: {loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "        return loss, {\"accuracy\": accuracy}\n",
        "    return evaluate_fn"
      ],
      "metadata": {
        "id": "BqhRoEZmv2VM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 8: Main federated learning function with validation tracking\n",
        "class SaveMetricsStrategy(fl.server.strategy.FedAvg):\n",
        "    def aggregate_evaluate(self, server_round, results, failures):\n",
        "        \"\"\"Aggregate evaluation accuracy.\"\"\"\n",
        "        if not results:\n",
        "            return None, {}\n",
        "\n",
        "        # Call aggregate_evaluate from base class (FedAvg) to aggregate loss and metrics\n",
        "        aggregated_loss, aggregated_metrics = super().aggregate_evaluate(server_round, results, failures)\n",
        "\n",
        "        # Calculate average accuracy\n",
        "        accuracies = [r.metrics[\"accuracy\"] for r in results]\n",
        "        avg_accuracy = sum(accuracies) / len(accuracies)\n",
        "\n",
        "        print(f\"Round {server_round} - Average validation accuracy: {avg_accuracy:.4f}\")\n",
        "\n",
        "        return aggregated_loss, aggregated_metrics\n",
        "\n",
        "def run_federated_learning(server_address=\"[::]:8080\"):\n",
        "    # Configuration parameters\n",
        "    config = {\n",
        "        'num_clients': 10,\n",
        "        'batch_size': 32,\n",
        "        'num_clients_per_round_fit': 3,\n",
        "        'num_clients_per_round_eval': 3,\n",
        "        'num_rounds': 5,\n",
        "        'num_classes': 10,\n",
        "        'config_fit': {\n",
        "            'lr': 0.01,\n",
        "            'momentum': 0.9,\n",
        "            'local_epochs': 1\n",
        "        }\n",
        "    }\n",
        "\n",
        "    print(\"Configuration:\")\n",
        "    for key, value in config.items():\n",
        "        print(f\"{key}: {value}\")\n",
        "\n",
        "    # Prepare dataset\n",
        "    print(\"Preparing dataset...\")\n",
        "    trainloaders, validateloaders, testloader = prepare_dataset(\n",
        "        config['num_clients'], config['batch_size']\n",
        "    )\n",
        "\n",
        "    # Define clients\n",
        "    client_fn = generate_client_fn(trainloaders, validateloaders, num_classes=10)\n",
        "\n",
        "    # Define strategy with validation tracking\n",
        "    strategy = SaveMetricsStrategy(\n",
        "        fraction_fit=1.0,\n",
        "        min_fit_clients=config['num_clients_per_round_fit'],\n",
        "        fraction_evaluate=1.0,\n",
        "        min_evaluate_clients=config['num_clients_per_round_eval'],\n",
        "        min_available_clients=config['num_clients'],\n",
        "        on_fit_config_fn=get_on_fit_config(config['config_fit']),\n",
        "        evaluate_fn=get_evaluate_fn(config['num_classes'], testloader)\n",
        "    )\n",
        "\n",
        "    # Start Flower server\n",
        "    print(\"Starting Flower server...\")\n",
        "\n",
        "    # Create client manager\n",
        "    client_manager = fl.server.SimpleClientManager()\n",
        "\n",
        "    # Initialize server\n",
        "    server = fl.server.Server(client_manager=client_manager, strategy=strategy)\n",
        "\n",
        "    # Start server\n",
        "    fl.server.start_server(\n",
        "        server_address=server_address,\n",
        "        config=fl.server.ServerConfig(num_rounds=config['num_rounds']),\n",
        "        strategy=strategy,\n",
        "        client_manager=client_manager\n",
        "    )"
      ],
      "metadata": {
        "id": "OW7cJboqv5AR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 9: Alternative simple approach with validation tracking\n",
        "def run_simple_federated_learning():\n",
        "    print(\"Running simplified federated learning...\")\n",
        "\n",
        "    # Configuration\n",
        "    num_clients = 3\n",
        "    batch_size = 32\n",
        "    num_rounds = 2\n",
        "\n",
        "    # Prepare dataset\n",
        "    trainloaders, validateloaders, testloader = prepare_dataset(num_clients, batch_size)\n",
        "\n",
        "    # Create a simple federated learning loop\n",
        "    global_model = Net(10)\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    for round in range(num_rounds):\n",
        "        print(f\"\\nRound {round + 1}/{num_rounds}\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "        # Train on each client\n",
        "        client_models = []\n",
        "        client_accuracies = []\n",
        "\n",
        "        for i in range(num_clients):\n",
        "            print(f\"  Training client {i + 1}/{num_clients}\")\n",
        "            client = FlowerClient(trainloaders[i], validateloaders[i], 10)\n",
        "\n",
        "            # Get global parameters\n",
        "            global_params = [val.cpu().numpy() for _, val in global_model.state_dict().items()]\n",
        "\n",
        "            # Train client\n",
        "            client_params, _, _ = client.fit(global_params, {\"lr\": 0.01, \"momentum\": 0.9, \"local_epochs\": 1})\n",
        "            client_models.append(client_params)\n",
        "\n",
        "            # Test client on validation set\n",
        "            client_loss, client_accuracy = test(client.model, validateloaders[i], device)\n",
        "            client_accuracies.append(client_accuracy)\n",
        "            print(f\"  Client {i + 1} validation accuracy: {client_accuracy:.4f}\")\n",
        "\n",
        "        # Print average client validation accuracy\n",
        "        avg_client_accuracy = sum(client_accuracies) / len(client_accuracies)\n",
        "        print(f\"  Average client validation accuracy: {avg_client_accuracy:.4f}\")\n",
        "\n",
        "        # Average client models (simple FedAvg)\n",
        "        averaged_params = []\n",
        "        for i in range(len(client_models[0])):\n",
        "            layer_params = []\n",
        "            for client_params in client_models:\n",
        "                layer_params.append(client_params[i])\n",
        "            averaged_layer = np.mean(layer_params, axis=0)\n",
        "            averaged_params.append(averaged_layer)\n",
        "\n",
        "        # Update global model\n",
        "        params_dict = zip(global_model.state_dict().keys(), averaged_params)\n",
        "        state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
        "        global_model.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "        # Test global model on test set\n",
        "        loss, accuracy = test(global_model, testloader, device)\n",
        "        print(f\"  Global model test accuracy: {accuracy:.4f}\")\n",
        "\n",
        "        # Test global model on validation sets (average across all clients)\n",
        "        global_val_accuracies = []\n",
        "        for i in range(num_clients):\n",
        "            val_loss, val_accuracy = test(global_model, validateloaders[i], device)\n",
        "            global_val_accuracies.append(val_accuracy)\n",
        "\n",
        "        avg_global_val_accuracy = sum(global_val_accuracies) / len(global_val_accuracies)\n",
        "        print(f\"  Global model average validation accuracy: {avg_global_val_accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "_01ICIBrv9IW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 10: Main function\n",
        "def main():\n",
        "    try:\n",
        "        # Try the simulation approach first\n",
        "        print(\"Starting federated learning with Flower...\")\n",
        "        run_federated_learning()\n",
        "    except SystemExit as e:\n",
        "        print(f\"Simulation approach failed: {e}\")\n",
        "        print(\"Trying alternative approach...\")\n",
        "        run_simple_federated_learning()\n",
        "    except ImportError as e:\n",
        "        print(f\"Simulation approach failed: {e}\")\n",
        "        print(\"Trying alternative approach...\")\n",
        "        run_simple_federated_learning()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKuh4u9Yv9tp",
        "outputId": "eebc68bd-04f1-42a5-a776-9c18325ba288"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting federated learning with Flower...\n",
            "Configuration:\n",
            "num_clients: 10\n",
            "batch_size: 32\n",
            "num_clients_per_round_fit: 3\n",
            "num_clients_per_round_eval: 3\n",
            "num_rounds: 5\n",
            "num_classes: 10\n",
            "config_fit: {'lr': 0.01, 'momentum': 0.9, 'local_epochs': 1}\n",
            "Preparing dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 11.4MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 335kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 2.71MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 6.39MB/s]\n",
            "\u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: flwr.server.start_server() is deprecated.\n",
            "\tInstead, use the `flower-superlink` CLI command to start a SuperLink as shown below:\n",
            "\n",
            "\t\t$ flower-superlink --insecure\n",
            "\n",
            "\tTo view usage and all available options, run:\n",
            "\n",
            "\t\t$ flower-superlink --help\n",
            "\n",
            "\tUsing `start_server()` is deprecated.\n",
            "\n",
            "            This is a deprecated feature. It will be removed\n",
            "            entirely in future versions of Flower.\n",
            "        \n",
            "WARNING:flwr:DEPRECATED FEATURE: flwr.server.start_server() is deprecated.\n",
            "\tInstead, use the `flower-superlink` CLI command to start a SuperLink as shown below:\n",
            "\n",
            "\t\t$ flower-superlink --insecure\n",
            "\n",
            "\tTo view usage and all available options, run:\n",
            "\n",
            "\t\t$ flower-superlink --help\n",
            "\n",
            "\tUsing `start_server()` is deprecated.\n",
            "\n",
            "            This is a deprecated feature. It will be removed\n",
            "            entirely in future versions of Flower.\n",
            "        \n",
            "\u001b[92mINFO \u001b[0m:      Starting Flower server, config: num_rounds=5, no round_timeout\n",
            "INFO:flwr:Starting Flower server, config: num_rounds=5, no round_timeout\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Flower server...\n",
            "Simulation approach failed: Port in server address [::]:8080 is already in use.\n",
            "Trying alternative approach...\n",
            "Running simplified federated learning...\n",
            "\n",
            "Round 1/2\n",
            "--------------------------------------------------\n",
            "  Training client 1/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Client 1 validation accuracy: 0.9665\n",
            "  Training client 2/3\n",
            "  Client 2 validation accuracy: 0.9640\n",
            "  Training client 3/3\n",
            "  Client 3 validation accuracy: 0.9635\n",
            "  Average client validation accuracy: 0.9647\n",
            "  Global model test accuracy: 0.9720\n",
            "  Global model average validation accuracy: 0.9677\n",
            "\n",
            "Round 2/2\n",
            "--------------------------------------------------\n",
            "  Training client 1/3\n",
            "  Client 1 validation accuracy: 0.9720\n",
            "  Training client 2/3\n",
            "  Client 2 validation accuracy: 0.9805\n",
            "  Training client 3/3\n",
            "  Client 3 validation accuracy: 0.9815\n",
            "  Average client validation accuracy: 0.9780\n",
            "  Global model test accuracy: 0.9846\n",
            "  Global model average validation accuracy: 0.9822\n"
          ]
        }
      ]
    }
  ]
}